apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: prometheus
    role: prometheus-example-rules
  name: prometheus-example-rules
  namespace: openshift-monitoring
spec:
  groups:
    - name: ./basic.rules
      rules:
        - alert: IstioIngressTrafficMissing
          annotations:
            summary: 'ingress gateway traffic missing'
            description: '[Critical]: ingress gateway traffic missing, likely other monitors are misleading, check client logs'
          expr: >
              absent(istio_requests_total{source_workload="istio-ingressgateway"})!=1
          for: 5m
          labels:
            component: istio
            notifier: slack
    - name: ./workload.rules
      labels:
        component: istio
        notifier: slack
      rules:
        - alert: IstioHTTP5xxRateHigh
          annotations:
            summary: '5xx rate too high'
            description: 'The HTTP 5xx errors rate higher than 0.05 in 5 mins'
          expr: >
            sum(irate(istio_requests_total{reporter="destination", response_code=~"5.*"}[5m])) / sum(irate(istio_requests_total{reporter="destination"}[5m])) > 0.05
          for: 5m
          labels:
            component: istio
            notifier: slack
        - alert: IstioWorkloadLatencyP99High
          expr: histogram_quantile(0.99, sum(irate(istio_request_duration_milliseconds_bucket{source_workload!="istio-ingressgateway"}[5m])) by (source_workload,namespace,destination_workload, le)) > 160
          for: 10m
          annotations:
            description: 'The workload request latency P99 > 160ms '
            message:  "Request duration has slowed down for workload: {{`{{$labels.source_workload}}`}} in namespace: {{`{{$labels.namespace}}`}}. Response duration is {{`{{$value}}`}} milliseconds"
          labels:
            component: istio
            notifier: slack
        - alert: IstioIngressLatencyP99High
          expr: histogram_quantile(0.99, sum(irate(istio_request_duration_milliseconds_bucket{source_workload="istio-ingressgateway"}[5m])) by (source_workload,namespace, le)) > 250
          for: 10m
          annotations:
            description: 'The ingress latency P99 > 250ms '
            message:  "Request duration has slowed down for ingress: {{`{{$labels.source_workload}}`}} in namespace: {{`{{$labels.namespace}}`}}. Response duration is {{`{{$value}}`}} milliseconds"
          labels:
            component: istio
            notifier: slack
    - name: ./infra.rules
      labels:
        component: istio
        notifier: slack
      rules:
        - alert: IstioProxyContainerCPUUsageHigh
          expr: (sum(rate(container_cpu_usage_seconds_total{namespace!="kube-system", container=~"istio-proxy", namespace!=""}[5m])) BY (namespace, pod, container) * 100) > 90
          for: 5m
          annotations:
            summary: "Proxy Container CPU usage (namespace {{ $labels.namespace }}) (pod {{ $labels.pod }}) (container {{ $labels.container }})  VALUE = {{ $value }}\n"
            description: "Proxy Container CPU usage is above 90%"
          labels:
            component: istio
            notifier: slack
        - alert: IstioProxyContainerMemoryUsageHigh
          expr: (sum(container_memory_working_set_bytes{namespace!="kube-system", container=~"istio-proxy", namespace!=""}) BY (container, pod, namespace)  / (sum(container_spec_memory_limit_bytes{namespace!="kube-system", container!="POD"}) BY (container, pod, namespace) > 0)* 100) > 90
          for: 5m
          annotations:
            summary: "Proxy Container Memory usage (namespace {{ $labels.namespace }}) (pod {{ $labels.pod }}) (container {{ $labels.container }})  VALUE = {{ $value }}\n"
            description: "Proxy Container Memory usage is above 90%"
          labels:
            component: istio
            notifier: slack
        - alert: IstioIstiodContainerCPUUsageHigh
          expr: (sum(rate(container_cpu_usage_seconds_total{namespace="istio-system", container="discovery"}[5m])) BY (pod) * 100) > 90
          for: 5m
          annotations:
            summary: "Istiod Container CPU usage (namespace {{ $labels.namespace }}) (pod {{ $labels.pod }}) (container {{ $labels.container }}) VALUE = {{ $value }}\n"
            description: "Isitod Container CPU usage is above 90%"
          labels:
            component: istio
            notifier: slack
        - alert: IstioIstiodMemoryUsageHigh
          expr: (sum(container_memory_working_set_bytes{namespace="istio-system", container="discovery"}) BY (pod)  / (sum(container_spec_memory_limit_bytes{namespace="istio-system", container="discovery"}) BY (pod) > 0)* 100) > 90
          for: 5m
          annotations:
            summary: "Istiod Container Memory usage (namespace {{ $labels.namespace }}) (pod {{ $labels.pod }}) (container {{ $labels.container }}) VALUE = {{ $value }}\n"
            description: "Istiod Container Memory usage is above 90%"
          labels:
            component: istio
            notifier: slack
    - name: ./controlplane.rules
      labels:
        component: istio
        notifier: slack
      rules:
        - alert: IstioIstiodContainerNotReady
          annotations:
            summary: 'istiod container not ready'
            description: 'container: discovery not running'
          expr: >
            kube_running_pod_ready{namespace="istio-system", pod=~"istiod.*"} == 0
          for: 5m
          labels:
            component: istio
            notifier: slack
        - alert: IstioIstiodReplicasNumber
          annotations:
            summary: 'istiod replicas are not 3'
            description: 'Replicas: istiod has not 3 replicas'
          expr: >
            sum(kube_running_pod_ready{namespace="istio-system", pod=~"istiod.*"}) != 3
          for: 5m
          labels:
            component: istio
            notifier: slack
        - alert: IstioIngress200RateLow
          annotations:
            summary: 'ingress gateway 200 rate drops'
            description: 'The expected rate is 100 per ns, the limit is set based on 15ns'
          expr: >
            sum(rate(istio_requests_total{reporter="source", source_workload="istio-ingressgateway",response_code="200"}[5m])) > 1490
          for: 5m
          labels:
            component: istio
            notifier: slack
    - name: "istio.recording-rules"
      interval: 5s
      rules:
        - record: "workload:istio_requests_total"
          expr: |
            sum without(instance, namespace, pod) (istio_requests_total)

        - record: "workload:istio_request_duration_milliseconds_count"
          expr: |
            sum without(instance, namespace, pod) (istio_request_duration_milliseconds_count)

        - record: "workload:istio_request_duration_milliseconds_sum"
          expr: |
            sum without(instance, namespace, pod) (istio_request_duration_milliseconds_sum)

        - record: "workload:istio_request_duration_milliseconds_bucket"
          expr: |
            sum without(instance, namespace, pod) (istio_request_duration_milliseconds_bucket)

    - name: k8s.rules
      rules:
        - expr: |
            sum(rate(container_cpu_usage_seconds_total{job="kubelet", metrics_path="/metrics/cadvisor", image!="", container!="POD"}[5m])) by (namespace)
          record: namespace:container_cpu_usage_seconds_total:sum_rate
        - expr: |
            sum by (cluster, namespace, pod, container) (
              rate(container_cpu_usage_seconds_total{job="kubelet", metrics_path="/metrics/cadvisor", image!="", container!="POD"}[5m])
            ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (
              1, max by(cluster, namespace, pod, node) (kube_pod_info)
            )
          record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
        - expr: |
            container_memory_working_set_bytes{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
            * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
              max by(namespace, pod, node) (kube_pod_info)
            )
          record: node_namespace_pod_container:container_memory_working_set_bytes
        - expr: |
            max by (cluster, namespace, workload, pod) (
              label_replace(
                label_replace(
                  kube_pod_owner{job="kube-state-metrics", owner_kind="ReplicaSet"},
                  "replicaset", "$1", "owner_name", "(.*)"
                ) * on(replicaset, namespace) group_left(owner_name) topk by(replicaset, namespace) (
                  1, max by (replicaset, namespace, owner_name) (
                    kube_replicaset_owner{job="kube-state-metrics"}
                  )
                ),
                "workload", "$1", "owner_name", "(.*)"
              )
            )
          labels:
            workload_type: deployment
          record: mixin_pod_workload